from langchain_core.messages import HumanMessage
from src.models.ollama_model import OllamaModel
from src.config import MODEL_DEEPSEEK_CODER
from src.utils.logger import get_logger
from langchain_core.prompts import ChatPromptTemplate
from src.tools.code_executor import code_executor_tool
from langchain.agents import AgentExecutor, create_tool_calling_agent

logger = get_logger(__name__)

def logic_expert_node(state, config):
    """
    3ï¸âƒ£ ğŸ§® DeepSeek Coder 1.3B (Tool / Logic Agent)
    
    GÃ¶revleri:
    - Matematik hesaplama
    - Python kod Ã¼retimi ve Ã§alÄ±ÅŸtÄ±rma
    - JSON Ã¼retme
    - MantÄ±ksal kurallar
    """
    logger.info("DeepSeek Logic Expert Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor")
    
    messages = state["messages"]
    last_message = messages[-1] # Genelde Llama veya Gemini'den gelir
    
    # DeepSeek Coder Modeli
    model_client = OllamaModel(model_name=MODEL_DEEPSEEK_CODER, temperature=0.0) # Kod iÃ§in 0 sÄ±caklÄ±k
    model = model_client.llm
    
    tools = [code_executor_tool]
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", """Sen DeepSeek Coder, bu sistemin 'MantÄ±k ve Kod UzmanÄ±'sÄ±n.
        GÃ¶revin:
        1. Gelen isteÄŸi python kodu yazarak veya mantÄ±ksal Ã§Ä±karsama ile Ã§Ã¶zmek.
        2. 'code_executor' aracÄ±nÄ± kullanarak kodu Ã§alÄ±ÅŸtÄ±r ve sonucu al.
        3. Sonucu net, kÄ±sa ve JSON veya yapÄ±landÄ±rÄ±lmÄ±ÅŸ formatta dÃ¶ndÃ¼r.
        4. Yorum yapma, sadece sonucu ver.
        """),
        ("placeholder", "{chat_history}"),
        ("human", "{input}"),
        ("placeholder", "{agent_scratchpad}"),
    ])
    
    agent = create_tool_calling_agent(model, tools, prompt)
    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)
    
    response = agent_executor.invoke({"input": last_message.content, "chat_history": messages[:-1]})
    
    return {"messages": [HumanMessage(content=response["output"], name="logic_expert")]}
