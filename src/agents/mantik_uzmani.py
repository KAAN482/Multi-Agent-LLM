from langchain_core.messages import HumanMessage
from src.models.ollama_model import OllamaModel
from src.config import MODEL_DEEPSEEK_CODER
from src.utils.logger import get_logger
from src.tools.code_executor import code_executor_tool
from langgraph.prebuilt import create_react_agent

logger = get_logger(__name__)

def logic_expert_node(state, config):
    """
    3ï¸âƒ£ ğŸ§® DeepSeek Coder 1.3B (Tool / Logic Agent)
    """
    logger.info("DeepSeek Logic Expert Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor")
    
    messages = state["messages"]
    
    # DeepSeek Coder Modeli (SÄ±caklÄ±k 0)
    model_client = OllamaModel(model_name=MODEL_DEEPSEEK_CODER, temperature=0.0)
    model = model_client.llm
    
    tools = [code_executor_tool]
    
    system_prompt = """Sen DeepSeek Coder, bu sistemin 'MantÄ±k ve Kod UzmanÄ±'sÄ±n.
    GÃ¶revin:
    1. Gelen isteÄŸi python kodu yazarak veya mantÄ±ksal Ã§Ä±karsama ile Ã§Ã¶zmek.
    2. 'code_executor' aracÄ±nÄ± kullanarak kodu Ã§alÄ±ÅŸtÄ±r ve sonucu al.
    3. Sonucu net, kÄ±sa ve JSON veya yapÄ±landÄ±rÄ±lmÄ±ÅŸ formatta dÃ¶ndÃ¼r.
    4. Yorum yapma, sadece sonucu ver.
    """
    
    # create_react_agent (Senkron invoke iÃ§in)
    agent = create_react_agent(model, tools, state_modifier=system_prompt)
    
    response = agent.invoke({"messages": messages})
    
    final_message = response["messages"][-1]
    
    return {"messages": [HumanMessage(content=final_message.content, name="logic_expert")]}
