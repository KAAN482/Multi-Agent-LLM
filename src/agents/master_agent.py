from langchain_core.messages import HumanMessage
from src.models.gemini_model import GeminiModel
from src.config import MODEL_GEMINI_MASTER
from src.utils.logger import get_logger
from langchain_core.prompts import ChatPromptTemplate
from src.tools.web_search import web_search_tool
from langchain.agents import AgentExecutor, create_tool_calling_agent

logger = get_logger(__name__)

async def master_agent_node(state, config):
    """
    2ï¸âƒ£ ğŸŒ Gemini 2.5 Flash (Master & Web Agent)
    
    GÃ¶revleri:
    - Web araÅŸtÄ±rmasÄ± (Eksik bilgi varsa)
    - Analist (Llama) ve MantÄ±k (DeepSeek) Ã§Ä±ktÄ±larÄ±nÄ±n kontrolÃ¼
    - Ã‡eliÅŸki tespiti
    - Final output Ã¼retimi (Akademik dÃ¼zenleme)
    """
    logger.info("Gemini Master Agent Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor")
    
    messages = state["messages"]
    
    # Mesaj geÃ§miÅŸini analiz et: Hangi ajanlar Ã§alÄ±ÅŸtÄ±?
    analyst_msg = next((m for m in reversed(messages) if m.name == "analyst"), None)
    logic_msg = next((m for m in reversed(messages) if m.name == "logic_expert"), None)
    
    # GiriÅŸ (Input) hazÄ±rlÄ±ÄŸÄ±
    user_input = messages[0].content
    context_str = ""
    if analyst_msg:
        context_str += f"\n[ANALÄ°ST RAPORU]:\n{analyst_msg.content}\n"
    if logic_msg:
        context_str += f"\n[MANTIK UZMANI SONUCU]:\n{logic_msg.content}\n"
        
    final_input = f"KullanÄ±cÄ± Sorusu: {user_input}\n\nEldeki BaÄŸlam:{context_str}\n\nGÃ¶revin: Bu bilgileri kullanarak nihai cevabÄ± Ã¼ret."

    # Gemini Modeli
    model_client = GeminiModel(model_name=MODEL_GEMINI_MASTER, temperature=0.7)
    model = model_client.llm
    
    tools = [web_search_tool]
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", """Sen Gemini 2.5 Flash, bu sistemin 'Master Agent'Ä±sÄ±n. En Ã¼st dÃ¼zey karar vericisin.
        
        GÃ¶revlerin:
        1. Llama (Analist) ve DeepSeek (MantÄ±k) ajanlarÄ±ndan gelen raporlarÄ± deÄŸerlendir.
        2. EÄŸer raporda eksik bilgi varsa veya gÃ¼ncel bilgi gerekiyorsa 'web_search' aracÄ±nÄ± kullan.
        3. Ajan Ã§Ä±ktÄ±larÄ± arasÄ±nda Ã§eliÅŸki varsa tespit et ve doÄŸrusunu bul.
        4. Sonucu akademik, yapÄ±landÄ±rÄ±lmÄ±ÅŸ ve detaylÄ± bir formatta kullanÄ±cÄ±ya sun.
        """),
        ("placeholder", "{chat_history}"),
        ("human", "{input}"),
        ("placeholder", "{agent_scratchpad}"),
    ])
    
    agent = create_tool_calling_agent(model, tools, prompt)
    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)
    
    # Gemini asenkron Ã§alÄ±ÅŸabilir
    response = await agent_executor.ainvoke({"input": final_input, "chat_history": []}) # Chat history master iÃ§in temiz olabilir veya Ã¶zet geÃ§ilebilir
    
    return {"messages": [HumanMessage(content=response["output"], name="master")]}
