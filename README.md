# Multi-Agent LLM AsistanÄ±

Bu proje, **Gemini 2.5 Flash** (Bulut) ve **Llama 3.2 3B** (Yerel) modellerini hibrit olarak kullanan, **LangGraph** ile optimize edilmiÅŸ 5 ajanlÄ± bir asistan sistemidir.

## ğŸš€ Ã–ne Ã‡Ä±kan Ã–zellikler

*   **Hibrit Model Mimarisi**: KarmaÅŸÄ±k akÄ±l yÃ¼rÃ¼tme iÃ§in Gemini, hÄ±zlÄ± ve Ã¼cretsiz yerel iÅŸlemler iÃ§in Llama 3.2.
*   **AkÄ±llÄ± Model SeÃ§ici**: GÃ¶rev tÃ¼rÃ¼ne ve metin uzunluÄŸuna gÃ¶re modeli otomatik belirleyerek API maliyetini ve gecikmeyi optimize eder.
*   **5 Uzman Ajan**: Supervisor, Researcher, Coder, Reviewer ve Formatter ajanlarÄ± LangGraph Ã¼zerinde iÅŸbirliÄŸi yapar.
*   **Entegre AraÃ§lar**: DuckDuckGo Web Arama, GÃ¼venli Python Kod Executor ve MCP (Model Context Protocol).
*   **GeliÅŸmiÅŸ Ä°zleme**: JSON formatlÄ± loglama ve LangFuse entegrasyonu.
*   **%100 Ãœcretsiz**: KullanÄ±lan tÃ¼m modeller ve araÃ§lar Ã¼cretsiz katmanlarÄ± veya yerel kaynaklarÄ± kullanÄ±r.

## ğŸ› ï¸ Kurulum

1.  **Depoyu KlonlayÄ±n**:
    ```bash
    git clone https://github.com/KAAN482/Multi-Agent-LLM.git
    cd Multi-Agent-LLM
    ```

2.  **Sanal Ortam OluÅŸturun**:
    ```bash
    python -m venv venv
    .\venv\Scripts\activate  # Windows
    # source venv/bin/activate # Linux/Mac
    ```

3.  **BaÄŸÄ±mlÄ±lÄ±klarÄ± YÃ¼kleyin**:
    ```bash
    pip install -r requirements.txt
    ```

4.  **Ollama ve Llama 3.2**:
    *   [ollama.com](https://ollama.com) adresinden Ollama'yÄ± indirin ve kurun.
    *   `ollama pull llama3.2:3b` komutuyla modeli indirin.

5.  **Ortam DeÄŸiÅŸkenleri**:
    *   `.env.example` dosyasÄ±nÄ± `.env` olarak kopyalayÄ±n.
    *   `GEMINI_API_KEY` deÄŸerini [Google AI Studio](https://aistudio.google.com/app/apikey) Ã¼zerinden alarak ekleyin.
    *   (Opsiyonel) LangFuse anahtarlarÄ±nÄ± ekleyin.

## ğŸ’» KullanÄ±m

Sistemi iki modda Ã§alÄ±ÅŸtÄ±rabilirsiniz:

**1. EtkileÅŸimli Mod (Sohbet):**
```bash
python main.py
```

**2. Tek Sorgu Modu:**
```bash
python main.py "Python'da fibonacci dizisinin ilk 10 elemanÄ±nÄ± hesapla" --mode auto
```

### Mod SeÃ§enekleri:
*   `auto`: GÃ¶reve gÃ¶re otomatik seÃ§im (VarsayÄ±lan).
*   `fast`: Yerel Llama modeline Ã¶ncelik verir.
*   `accurate`: KarmaÅŸÄ±k gÃ¶revler iÃ§in Gemini 2.5 Flash'a Ã¶ncelik verir.

## ğŸ§ª Testler

TÃ¼m birim testlerini Ã§alÄ±ÅŸtÄ±rmak iÃ§in:
```bash
python -m pytest tests/ -v
```

## ğŸ—ï¸ Mimari

Proje, LangGraph Ã¼zerinde tanÄ±mlanmÄ±ÅŸ bir durum grafiÄŸi kullanÄ±r. **Supervisor** ajanÄ±, kullanÄ±cÄ± query'sini analiz ederek Researcher (AraÅŸtÄ±rma) veya Coder (Hesaplama/Kodlama) ajanlarÄ±na iÅŸ daÄŸÄ±tÄ±r. SonuÃ§lar **Reviewer** tarafÄ±ndan denetlenir ve **Formatter** tarafÄ±ndan son kullanÄ±cÄ± formatÄ±na (Markdown) dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r.

---
**GeliÅŸtirici**: [KAAN482](https://github.com/KAAN482)
